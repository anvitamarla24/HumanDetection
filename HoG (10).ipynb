{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.img = np.full((160, 96), 0)\n",
    "        self.img_array = np.full((160, 96), 0)\n",
    "        self.gray = np.full((160, 96), 0)\n",
    "        self.gray_array = np.full((160, 96), 0)\n",
    "        \n",
    "        self.G_X = np.full((160, 96), 0)\n",
    "        self.G_Y = np.full((160, 96), 0)\n",
    "        self.g_x = np.full((160, 96), 0)\n",
    "        self.g_y = np.full((160, 96), 0)\n",
    "        self.g_mag = np.full((160, 96), 0)\n",
    "        self.sobel_image = np.full((160, 96), 0)\n",
    "        \n",
    "        self.theta = np.full((160, 96), 0)       \n",
    "        \n",
    "        self.path = path\n",
    "        self.img_array = np.full((160, 96), 0)\n",
    "        self.image_read()\n",
    "        self.gray = self.rgb2gray(self.img_array)\n",
    "        self.image_write(self.gray)\n",
    "        \n",
    "        self.g_x, self.g_y, self.sobel_output = np.round(self.sobels_operator(self.gray))\n",
    "        self.theta = self.gradient_angles(self.gray_array, self.g_x, self.g_y)\n",
    "#         print(self.g_x[28][28])\n",
    "#         print(self.g_y[28][28])\n",
    "#         print(self.theta[28][28])\n",
    "        \n",
    "#         return  self.img_array, self.gray_array, self.g_mag, self.theta\n",
    "        \n",
    "#         self\n",
    "    \n",
    "    def image_read(self):\n",
    "        self.img = cv2.imread(self.path)  \n",
    "        self.img_array = np.array(self.img, dtype=float)\n",
    "#         self.gray = self.rgb2gray(self.img)\n",
    "#         self.\n",
    "    \n",
    "    def rgb2gray(self, rgb):\n",
    "        return np.round(np.dot(rgb[...,:3], [0.299, 0.587, 0.114]))\n",
    "    \n",
    "    def image_write(self, gray):\n",
    "        self.img_gray = cv2.imwrite('C:/Users/anvit/OneDrive/Desktop/HoG/Test_results/test_gray.bmp', self.gray)\n",
    "        self.gray_array = np.array(gray, dtype=float)\n",
    "#         return self.gray_array\n",
    "\n",
    "    #sobels operator\n",
    "    def sobels_operator(self, inp):\n",
    "        self.inp = inp\n",
    "        g_x = np.array([[-1,0,1],\n",
    "                       [-2,0,2],\n",
    "                       [-1,0,1]])\n",
    "        g_y = np.array([[1,2,1],\n",
    "                       [0,0,0],\n",
    "                       [-1,-2,-1]])\n",
    "    \n",
    "        #Horizontal Gradient \n",
    "        self.G_X = self.conv_sobel(self.inp,g_x)\n",
    "        #Saving the image\n",
    "        cv2.imwrite('C:/Users/anvit/OneDrive/Desktop/HoG/Test_results/test_gray_sobelGX.bmp', self.G_X)\n",
    "       \n",
    "        #Vertical Gradient\n",
    "        self.G_Y = self.conv_sobel(self.inp,g_y)\n",
    "        #saving the image\n",
    "        cv2.imwrite('C:/Users/anvit/OneDrive/Desktop/HoG/Test_results/test_gray_sobelGY.bmp', self.G_Y)\n",
    "    \n",
    "        #Gradient Magnitude\n",
    "        self.g_mag = np.sqrt(np.square(self.G_X) + np.square(self.G_Y))\n",
    "        #saving the image\n",
    "        cv2.imwrite('C:/Users/anvit/OneDrive/Desktop/HoG/Test_results/test_gray_sobel.bmp', self.g_mag)    \n",
    "        return self.G_X, self.G_Y, self.g_mag\n",
    "\n",
    "    #convolution done by implementing using 2D directly\n",
    "    def conv_sobel(self,x,y):\n",
    "        \n",
    "        row_size = x.shape[0]\n",
    "        column_size = x.shape[1]        \n",
    "        conv_img = np.zeros((row_size, column_size), dtype=np.float)\n",
    "        \n",
    "        for a in range(0, row_size - 2):\n",
    "            for b in range(0, column_size - 2):\n",
    "                \n",
    "                conv_img[a + 1][b + 1] = (np.sum(x[a: a + 3, b: b + 3] * y)) / 4\n",
    "\n",
    "        return conv_img\n",
    "    \n",
    "    def gradient_angles(self, gray_array, g_x, g_y):\n",
    "        #Finding the Gradient Angles i.e., theta\n",
    "        print(self.gray_array.shape[0])\n",
    "        #arctan2 is tan inverse, which gives us results in radians with [-pi to pi]\n",
    "        self.theta = np.zeros((self.gray_array.shape[0],self.gray_array.shape[1]))\n",
    "        for i in range(self.gray_array.shape[0]):\n",
    "            for j in range(0, self.gray_array.shape[1]):\n",
    "                if(self.g_y[i][j] == 0 and self.g_x[i][j] == 0):\n",
    "                    self.theta[i][j] = 0\n",
    "                elif(self.g_y[i][j] > 0 and self.g_x[i][j] == 0):\n",
    "                    self.theta[i][j] = 90\n",
    "                elif(self.g_y[i][j] < 0 and self.g_x[i][j] == 0):\n",
    "                    self.theta[i][j] = -90\n",
    "                elif(self.g_y[i][j] == 0):\n",
    "                    self.theta[i][j] = 0\n",
    "                else:\n",
    "                    if(self.g_x[i][j] == 0):\n",
    "                        print('here')\n",
    "                    self.theta[i][j] = np.arctan2(self.g_y[i][j],self.g_x[i][j])\n",
    "    \n",
    "        #Converting radians to degrees\n",
    "        self.theta = np.rad2deg(self.theta)\n",
    "        #converting all the negatives into positives by adding 360 so the range is now [0 to 360]\n",
    "        for i in range(0, self.gray_array.shape[0]):\n",
    "            for j in range(0, self.gray_array.shape[1]):\n",
    "                if(self.theta[i][j] < 0):\n",
    "                    self.theta[i][j] += 360\n",
    "                    \n",
    "        return self.theta        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Histogram:\n",
    "    def __init__(self, mag_block, theta_block):\n",
    "        self.center = np.array([0,20,40,60,80,100,120,140,160])\n",
    "#         4 histograms of 9 bins each - per block\n",
    "        self.bins = np.zeros((4,9), dtype=float)\n",
    "        self.cell_size = 8\n",
    "        self.cells = []\n",
    "        self.t_cells = []\n",
    "        self.m_cells = []\n",
    "        self.flattened = []\n",
    "        self.theta_block = theta_block\n",
    "        self.mag_block = mag_block\n",
    "        self.convert_block_2_cell(mag_block,theta_block)\n",
    "#         c=0\n",
    "#         print(c)\n",
    "        self.generate_features(self.m_cells, self.t_cells)\n",
    "        self.norm_hog()\n",
    "        self.flattened_bins()\n",
    "        \n",
    "    def flattened_bins(self):\n",
    "        for bin in self.bins:\n",
    "            for item in bin:\n",
    "                self.flattened.append(item)\n",
    "        \n",
    "    \n",
    "    def norm_hog(self):\n",
    "        \n",
    "        summation = 0\n",
    "        for bin in self.bins:\n",
    "            for j in range(len(bin)):\n",
    "                summation += bin[j] ** 2\n",
    "        \n",
    "        dist = summation ** 0.5\n",
    "                   \n",
    "        for bin in self.bins:\n",
    "            for j in range(len(bin)):\n",
    "                if(dist == 0):\n",
    "                    continue\n",
    "                else:\n",
    "                    bin[j] /= dist\n",
    "\n",
    "    \n",
    "    def convert_block_2_cell(self, mag_block, theta_block):\n",
    "        c=0\n",
    "        for m in range(0,theta_block.shape[0], self.cell_size):\n",
    "                for n in range(0, theta_block.shape[1], self.cell_size):\n",
    "                    \n",
    "                    m_cell = np.zeros((self.cell_size,self.cell_size))\n",
    "                    t_cell = np.zeros((self.cell_size,self.cell_size))\n",
    "                    \n",
    "                    for p in range(self.cell_size):\n",
    "                        for q in range(self.cell_size):\n",
    "                            \n",
    "                            m_cell[p][q] = mag_block[m+p][n+q]\n",
    "                            t_cell[p][q] = theta_block[m+p][n+q]\n",
    "                     \n",
    "                    c+=1\n",
    "                    self.m_cells.append(m_cell)\n",
    "                    self.t_cells.append(t_cell)\n",
    "#         print(c)\n",
    "    \n",
    "    def generate_features(self, m_cells, t_cells):\n",
    "        \n",
    "        for i in range(len(t_cells)):\n",
    "            for j in range(len(t_cells[i])):\n",
    "                for k in range(len(t_cells[i][j])):\n",
    "                    self.cal_hist(m_cells[i][j][k],t_cells[i][j][k], self.bins[i]) \n",
    "                \n",
    "# HANDLE EDGE CASE : -20,10       \n",
    "    def cal_hist(self, mag, angle, bins):       \n",
    "        \n",
    "#         COMPUTE THE DISTANCE TO ADD THE MAG WRT THE CENTER\n",
    "        if(angle >= 180):\n",
    "            angle -= 180\n",
    "#         now we have all unsigned angles\n",
    "# new case to consider: if angle is >=160 first = bin 9 and second is bin 1\n",
    "        \n",
    "        if(angle >= 160):\n",
    "            first_bin = 8\n",
    "            second_bin = 0\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag \n",
    "#         edge care , if angle is >=350 it's between bins 1 and 9\n",
    "        \n",
    "        if(angle >= 0 and angle < 20):\n",
    "            first_bin = 0\n",
    "            second_bin = 1\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag\n",
    "        \n",
    "        if(angle >= 20 and angle < 40):\n",
    "            first_bin = 1\n",
    "            second_bin = 2\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag\n",
    "            \n",
    "        if(angle >= 40 and angle < 60):\n",
    "            first_bin = 2\n",
    "            second_bin = 3\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag\n",
    "            \n",
    "        if(angle >= 60 and angle < 80):\n",
    "            first_bin = 3\n",
    "            second_bin = 4\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag\n",
    "        \n",
    "        if(angle >= 80 and angle < 100):\n",
    "            first_bin = 4\n",
    "            second_bin = 5\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag\n",
    "        \n",
    "        if(angle >= 100 and angle < 120):\n",
    "            first_bin = 5\n",
    "            second_bin = 6\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag\n",
    "        \n",
    "        if(angle >= 120 and angle < 140):\n",
    "            first_bin = 6\n",
    "            second_bin = 7\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag\n",
    "         \n",
    "        if(angle >= 140 and angle < 160):\n",
    "            first_bin = 7\n",
    "            second_bin = 8\n",
    "            percentage = self.calc_distance(angle, self.center[first_bin])\n",
    "            bins[first_bin] += (1-percentage) * mag\n",
    "            bins[second_bin] += percentage * mag\n",
    "            \n",
    "    def calc_distance(self, angle, center):        \n",
    "        percent = (np.absolute(angle - center))/20\n",
    "        return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h_feature(mag, theta): \n",
    "    descriptor = []\n",
    "    cell_size = 8\n",
    "    block_size = 16\n",
    "    block_overlap = 8\n",
    "    assert(mag.shape[0] == theta.shape[0])\n",
    "    assert(mag.shape[1] == theta.shape[1])\n",
    "    b=0\n",
    "    c=0\n",
    "    \n",
    "#     generating blocks from pixels\n",
    "    for i in range(0,theta.shape[0]-cell_size, cell_size):\n",
    "        for j in range(0,theta.shape[1]-cell_size, cell_size):\n",
    "            \n",
    "            m_block = np.zeros((block_size,block_size))\n",
    "            t_block = np.zeros((block_size,block_size))\n",
    "            \n",
    "            for k in range(block_size):\n",
    "                for l in range(block_size):  \n",
    "                    \n",
    "                    m_block[k][l] = mag[i+k][j+l]\n",
    "                    t_block[k][l] = theta[i+k][j+l]\n",
    "            b +=1\n",
    "\n",
    "            hist_obj = Histogram(m_block,t_block)\n",
    "            for item in hist_obj.flattened:\n",
    "                descriptor.append(item)\n",
    "    print(b)\n",
    "#     print(c)\n",
    "    return descriptor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h_feature_output = np.array(h_feature(sobel_output,theta))\n",
    "# print(np.concatenate(h_feature_output).ravel().tolist())\n",
    "# print(h_feature_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBP:\n",
    "    def __init__(self, gray_block):\n",
    "        self.mag = gray_block\n",
    "        self.bins = np.zeros((59,), dtype=float)\n",
    "        self.generate_features(gray_block)\n",
    "        self.norm_lbp()\n",
    "        \n",
    "    def norm_lbp(self):\n",
    "        for i in range(len(self.bins)):\n",
    "            self.bins[i] = self.bins[i] / 256\n",
    "    \n",
    "    def generate_features(self,gray_block):\n",
    "        for i in range(gray_block.shape[0]):\n",
    "            for j in range(gray_block.shape[1]):\n",
    "                self.compute_LBP_pattern(i,j,gray_block)\n",
    "        \n",
    "#     def norm_lbp(self):\n",
    "#         for i in range(len(self.bins)):\n",
    "#             self.bins[i] = self.bins[i] / 256\n",
    "        \n",
    "    def compute_LBP_pattern(self,i, j,gray_block):\n",
    "        x = gray_block\n",
    "        pattern = ''\n",
    "        \n",
    "        try:\n",
    "            if(x[i-1][j-1] > x[i][j]):\n",
    "                pattern += '1'\n",
    "            else:\n",
    "                pattern += '0'\n",
    "                \n",
    "            if(x[i-1][j] > x[i][j]):\n",
    "                pattern += '1'\n",
    "            else:\n",
    "                pattern += '0'\n",
    "                \n",
    "            if(x[i-1][j+1] > x[i][j]):\n",
    "                pattern += '1'\n",
    "            else:\n",
    "                pattern += '0'\n",
    "                \n",
    "            if(x[i][j+1] > x[i][j]):\n",
    "                pattern += '1'\n",
    "            else:\n",
    "                pattern += '0'\n",
    "                \n",
    "            if(x[i+1][j+1] > x[i][j]):\n",
    "                pattern += '1'\n",
    "            else:\n",
    "                pattern += '0'\n",
    "            \n",
    "            if(x[i+1][j] > x[i][j]):\n",
    "                pattern += '1'\n",
    "            else:\n",
    "                pattern += '0'\n",
    "            \n",
    "            if(x[i+1][j-1] > x[i][j]):\n",
    "                pattern += '1'\n",
    "            else:\n",
    "                pattern += '0'\n",
    "            \n",
    "            if(x[i][j-1] > x[i][j]):\n",
    "                pattern += '1'\n",
    "            else:\n",
    "                pattern += '0'\n",
    "                \n",
    "            self.append_to_bins(pattern)\n",
    "            \n",
    "        except IndexError:\n",
    "            pattern = '00000101'\n",
    "            self.append_to_bins(pattern)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def append_to_bins(self, lbp_pattern):        \n",
    "        decimal = int(lbp_pattern, 2)\n",
    "        patterns = {\n",
    "            0: 0,\n",
    "            1: 1,\n",
    "            2: 2,\n",
    "            3: 3,\n",
    "            4: 4,\n",
    "            6: 5,\n",
    "            7: 6,\n",
    "            8: 7,\n",
    "            12: 8,\n",
    "            14: 9,\n",
    "            15: 10,\n",
    "            16: 11,\n",
    "            24: 12,\n",
    "            28: 13,\n",
    "            30: 14,\n",
    "            31: 15,\n",
    "            32: 16,\n",
    "            48: 17,\n",
    "            56: 18,\n",
    "            60: 19,\n",
    "            62: 20,\n",
    "            63: 21,\n",
    "            64: 22,\n",
    "            96: 23,\n",
    "            112: 24,\n",
    "            120: 25,\n",
    "            124: 26,\n",
    "            126: 27,\n",
    "            127: 28,\n",
    "            128: 29,\n",
    "            129: 30,\n",
    "            131: 31,\n",
    "            135: 32,\n",
    "            143: 33,\n",
    "            159: 34,\n",
    "            191: 35,\n",
    "            192: 36,\n",
    "            193: 37,\n",
    "            195: 38,\n",
    "            199: 39,\n",
    "            207: 40,\n",
    "            223: 41,\n",
    "            224: 42,\n",
    "            225: 43,\n",
    "            227: 44,\n",
    "            231: 45,\n",
    "            239: 46,\n",
    "            240: 47,\n",
    "            241: 48,\n",
    "            243: 49,\n",
    "            247: 50,\n",
    "            248: 51,\n",
    "            249: 52,\n",
    "            251: 53,\n",
    "            252: 54,\n",
    "            253: 55,\n",
    "            254: 56,\n",
    "            255: 57\n",
    "        }\n",
    "        bin_number = patterns.get(decimal, 58)\n",
    "        self.bins[bin_number] += 1   \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LBP_feature(gray):\n",
    "    lbp_descriptor = []\n",
    "    cell_size = 8\n",
    "    block_size = 16\n",
    "    block_overlap = 8\n",
    "    b=0\n",
    "#     c=0\n",
    "    \n",
    "#     generating blocks from pixels   \n",
    "    for i in range(0,gray.shape[0],block_size):\n",
    "        for j in range(0,gray.shape[1],block_size):\n",
    "            \n",
    "            gray_block = np.zeros((block_size,block_size))\n",
    "            \n",
    "            for p in range(block_size):\n",
    "                for q in range(block_size):\n",
    "                    \n",
    "                    gray_block[p][q] = gray[i+p][j+q]\n",
    "            \n",
    "            \n",
    "            b+=1\n",
    "            lbp_obj1 = LBP(gray_block)\n",
    "            lbp_descriptor.append(lbp_obj1.bins)\n",
    "#     print(b)        \n",
    "    return lbp_descriptor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbp_output = LBP_feature(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(lbp_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HOG_NeuralNetwork:\n",
    "    def __init__(self, human_feature_vectors, non_human_feature_vectors, epochs = 3, alpha = 0.01, input_layer_neurons = 7524, hidden_layer_neurons = 200, output_layer_neurons = 1):\n",
    "        \n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.input_layer_neurons = input_layer_neurons\n",
    "        self.hidden_layer_neurons = hidden_layer_neurons\n",
    "        self.output_layer_neurons = output_layer_neurons\n",
    "        \n",
    "#         self.output_hidden_layer = np.full((2, 1), 0.0)\n",
    "#         self.pred_output = np.full((, 1), 0.0)\n",
    "#         self.err = np.full((2, 1), 0.0)\n",
    "        \n",
    "        #assigning random weights\n",
    "#         self.hidden_layer_weights = np.random.randn(-0.5, 0.5, size = (self.input_layer_neurons,self.hidden_layer_neurons))\n",
    "#         self.output_layer_weights = np.random.randn(-0.5, 0.5, size = (self.hidden_layer_neurons,self.output_layer_neurons))\n",
    "        self.hidden_layer_weights =  (np.random.random_sample((self.input_layer_neurons,self.hidden_layer_neurons)) -0.5) * 2 * self.alpha\n",
    "        self.output_layer_weights =  (np.random.random_sample((self.hidden_layer_neurons,self.output_layer_neurons)) - 0.5) * 2 * self.alpha\n",
    "    \n",
    "        #assigning random bias       \n",
    "        self.hidden_layer_bias = np.full((1,self.hidden_layer_neurons), -1.0, dtype = float)\n",
    "        self.output_layer_bias = np.full((1,self.output_layer_neurons), -1.0, dtype = float)\n",
    "        \n",
    "#         self.human_feature_vectors = np.array([[0,0],[0,1],[1,0], [1,1]])\n",
    "        self.human_feature_vectors = human_feature_vectors\n",
    "        self.non_human_feature_vectors = non_human_feature_vectors\n",
    "        \n",
    "        self.output_hidden_layer = None\n",
    "        self.pred_output = None\n",
    "        self.pred_output_delta = None\n",
    "        self.hidden_layer_output_delta = None\n",
    "        \n",
    "        \n",
    "        print(self.non_human_feature_vectors.shape)\n",
    "        self.train_nn()\n",
    "        \n",
    "    # Sigmoid function for the output neuron \n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1 + np.exp(-x))\n",
    "        \n",
    "    # Derivative of Sigmoid in terms of itself:\n",
    "    def derivative_of_sigmoid(self, x):\n",
    "        return x * (1 - x)\n",
    "        \n",
    "    # ReLu function for the hidden neurons\n",
    "    def relu(self, x):\n",
    "        y = x.copy()\n",
    "        y[x<0] = 0\n",
    "        return y\n",
    "        \n",
    "    # Derivative of ReLU in terms of itself is:    \n",
    "    def derivative_of_relu(self, x):\n",
    "        y = x.copy()\n",
    "        y[x>0] = 1\n",
    "        y[x<=0] = 0\n",
    "        return y\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        \n",
    "        self.inputs = inputs\n",
    "#         h_layer_a = np.dot(self.inputs,self.hidden_layer_weights) + self.hidden_layer_bias\n",
    "        self.output_hidden_layer = self.relu(np.dot(self.inputs,self.hidden_layer_weights) + self.hidden_layer_bias)\n",
    "\n",
    "#         o_layer_a = np.dot(self.output_hidden_layer, self.output_layer_weights) + self.output_layer_bias\n",
    "        \n",
    "        self.pred_output = self.sigmoid(np.dot(self.output_hidden_layer, self.output_layer_weights) + self.output_layer_bias)\n",
    "        \n",
    "    def backpropogation(self, target_output):\n",
    "        \n",
    "        final_error = target_output - self.pred_output\n",
    "#         print('final error', final_error)\n",
    "        self.err = np.absolute(target_output - self.pred_output).sum()\n",
    "        self.pred_output_delta = final_error * self.derivative_of_sigmoid(self.pred_output)\n",
    "        \n",
    "        h_layer_error = self.pred_output_delta.dot(self.output_layer_weights.T)\n",
    "        self.hidden_layer_output_delta = h_layer_error * self.derivative_of_relu(self.output_hidden_layer)\n",
    "            \n",
    "    def update(self, inputs):\n",
    "            \n",
    "        #Updating weights and bias\n",
    "#         self.inputs = inputs\n",
    "        self.output_layer_weights = self.output_layer_weights + self.output_hidden_layer.T.dot(self.pred_output_delta) * self.alpha\n",
    "        self.output_layer_bias = self.output_layer_bias + np.sum(self.pred_output_delta,axis = 1, keepdims=True) * self.alpha\n",
    "    \n",
    "        self.hidden_layer_weights = self.hidden_layer_weights + inputs.T.dot(self.hidden_layer_output_delta) * self.alpha\n",
    "        self.hidden_layer_bias = self.hidden_layer_bias + np.sum(self.hidden_layer_output_delta, axis = 1, keepdims=True) * self.alpha\n",
    "\n",
    "        \n",
    "    def train_nn(self):\n",
    "        \n",
    "        avg_error = 0\n",
    "        for _ in range(self.epochs):\n",
    "            target_output = np.array([[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0],[1.0]]) \n",
    "            self.feedforward(self.human_feature_vectors)\n",
    "            self.backpropogation(target_output)\n",
    "            self.update(self.human_feature_vectors)\n",
    "#             if(np.absolute(avg_error - self.err)<= 0.1):\n",
    "#                 break\n",
    "            avg_error += self.err\n",
    "#             if(avg_error <= 0.1):\n",
    "#                 break\n",
    "        print('Predicted output after training Negative Images:\\n', self.pred_output)\n",
    "        print('Average Error:\\n', avg_error/len(self.human_feature_vectors))\n",
    "        \n",
    "        #save anything from training positive here         \n",
    "        \n",
    "        # reset values for negative features\n",
    "\n",
    "#         #assigning random weights\n",
    "#         self.hidden_layer_weights = np.random.uniform(-0.5, 0.5, size = (self.input_layer_neurons,self.hidden_layer_neurons))\n",
    "#         self.output_layer_weights = np.random.uniform(-0.5, 0.5, size = (self.hidden_layer_neurons,self.output_layer_neurons))\n",
    "\n",
    "#         #assigning random bias       \n",
    "#         self.hidden_layer_bias = np.random.uniform(-1, -1, size = (1,self.hidden_layer_neurons))\n",
    "#         self.output_layer_bias = np.random.uniform(-1, -1, size = (1,self.output_layer_neurons))\n",
    "\n",
    "#         self.pred_output = 0\n",
    "        \n",
    "# #         self.pred_output = np.full((2, 1), 0.0)\n",
    "        \n",
    "#         avg_error = 0\n",
    "#         for _ in range(self.epochs):\n",
    "#             target_output = np.full((10,1),0.0)\n",
    "#             self.feedforward(self.non_human_feature_vectors)\n",
    "#             self.backpropogation(target_output)\n",
    "#             self.update(self.non_human_feature_vectors)\n",
    "#             avg_error += self.err\n",
    "        \n",
    "#         print('Predicted output after training Negative Images:\\n', self.pred_output)\n",
    "#         print('Average Error:\\n', avg_error/len(self.non_human_feature_vectors))\n",
    "        \n",
    "# #         save anything from training negative here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00000053a_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 0.0720878   0.0004209   0.00069536 ...  0.00124067  0.00056821\n",
      "  -0.04444839]]\n",
      "00000057a_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 0.0720878   0.0004209   0.00069536 ...  0.00124067  0.00056821\n",
      "  -0.04444839]\n",
      " [ 0.          0.          0.         ...  0.00383367  0.00569453\n",
      "   0.00495882]]\n",
      "00000062a_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 7.20877970e-02  4.20899586e-04  6.95361453e-04 ...  1.24067096e-03\n",
      "   5.68206803e-04 -4.44483916e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.83367365e-03\n",
      "   5.69453250e-03  4.95882413e-03]\n",
      " [ 3.00071134e-01  1.17301771e-04  6.42556211e-04 ...  1.02780241e-03\n",
      "   4.23757265e-04 -3.90654615e-01]]\n",
      "00000091a_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 7.20877970e-02  4.20899586e-04  6.95361453e-04 ...  1.24067096e-03\n",
      "   5.68206803e-04 -4.44483916e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.83367365e-03\n",
      "   5.69453250e-03  4.95882413e-03]\n",
      " [ 3.00071134e-01  1.17301771e-04  6.42556211e-04 ...  1.02780241e-03\n",
      "   4.23757265e-04 -3.90654615e-01]\n",
      " [ 4.73830129e-01  0.00000000e+00  3.32755520e-05 ...  4.63581952e-04\n",
      "   1.31817731e-04 -4.00897323e-01]]\n",
      "00000093a_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 7.20877970e-02  4.20899586e-04  6.95361453e-04 ...  1.24067096e-03\n",
      "   5.68206803e-04 -4.44483916e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.83367365e-03\n",
      "   5.69453250e-03  4.95882413e-03]\n",
      " [ 3.00071134e-01  1.17301771e-04  6.42556211e-04 ...  1.02780241e-03\n",
      "   4.23757265e-04 -3.90654615e-01]\n",
      " [ 4.73830129e-01  0.00000000e+00  3.32755520e-05 ...  4.63581952e-04\n",
      "   1.31817731e-04 -4.00897323e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.85315061e-03\n",
      "   5.05433907e-04 -4.43227202e-01]]\n",
      "01-03e_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 7.20877970e-02  4.20899586e-04  6.95361453e-04 ...  1.24067096e-03\n",
      "   5.68206803e-04 -4.44483916e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.83367365e-03\n",
      "   5.69453250e-03  4.95882413e-03]\n",
      " [ 3.00071134e-01  1.17301771e-04  6.42556211e-04 ...  1.02780241e-03\n",
      "   4.23757265e-04 -3.90654615e-01]\n",
      " [ 4.73830129e-01  0.00000000e+00  3.32755520e-05 ...  4.63581952e-04\n",
      "   1.31817731e-04 -4.00897323e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.85315061e-03\n",
      "   5.05433907e-04 -4.43227202e-01]\n",
      " [ 7.62390416e-03  5.81234227e-03  3.61268738e-03 ...  1.93791774e-03\n",
      "   1.18198487e-03 -5.08549557e-01]]\n",
      "no_person__no_bike_213_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 7.20877970e-02  4.20899586e-04  6.95361453e-04 ...  1.24067096e-03\n",
      "   5.68206803e-04 -4.44483916e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.83367365e-03\n",
      "   5.69453250e-03  4.95882413e-03]\n",
      " [ 3.00071134e-01  1.17301771e-04  6.42556211e-04 ...  1.02780241e-03\n",
      "   4.23757265e-04 -3.90654615e-01]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.85315061e-03\n",
      "   5.05433907e-04 -4.43227202e-01]\n",
      " [ 7.62390416e-03  5.81234227e-03  3.61268738e-03 ...  1.93791774e-03\n",
      "   1.18198487e-03 -5.08549557e-01]\n",
      " [ 2.87742187e-02  9.96124710e-04  8.19479457e-04 ...  2.29334322e-02\n",
      "   2.95734749e-02 -2.03343695e-01]]\n",
      "no_person__no_bike_219_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 7.20877970e-02  4.20899586e-04  6.95361453e-04 ...  1.24067096e-03\n",
      "   5.68206803e-04 -4.44483916e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.83367365e-03\n",
      "   5.69453250e-03  4.95882413e-03]\n",
      " [ 3.00071134e-01  1.17301771e-04  6.42556211e-04 ...  1.02780241e-03\n",
      "   4.23757265e-04 -3.90654615e-01]\n",
      " ...\n",
      " [ 7.62390416e-03  5.81234227e-03  3.61268738e-03 ...  1.93791774e-03\n",
      "   1.18198487e-03 -5.08549557e-01]\n",
      " [ 2.87742187e-02  9.96124710e-04  8.19479457e-04 ...  2.29334322e-02\n",
      "   2.95734749e-02 -2.03343695e-01]\n",
      " [ 5.01603488e-01  1.85171506e-02  9.41596130e-03 ...  1.95964581e-02\n",
      "   6.74493141e-03  5.85352367e-03]]\n",
      "no_person__no_bike_247_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 7.20877970e-02  4.20899586e-04  6.95361453e-04 ...  1.24067096e-03\n",
      "   5.68206803e-04 -4.44483916e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.83367365e-03\n",
      "   5.69453250e-03  4.95882413e-03]\n",
      " [ 3.00071134e-01  1.17301771e-04  6.42556211e-04 ...  1.02780241e-03\n",
      "   4.23757265e-04 -3.90654615e-01]\n",
      " ...\n",
      " [ 2.87742187e-02  9.96124710e-04  8.19479457e-04 ...  2.29334322e-02\n",
      "   2.95734749e-02 -2.03343695e-01]\n",
      " [ 5.01603488e-01  1.85171506e-02  9.41596130e-03 ...  1.95964581e-02\n",
      "   6.74493141e-03  5.85352367e-03]\n",
      " [ 3.51781247e-02  1.31016833e-02  2.94608308e-03 ...  1.08392660e-03\n",
      "   8.95282153e-04 -5.93716913e-01]]\n",
      "no_person__no_bike_259_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 7.20877970e-02  4.20899586e-04  6.95361453e-04 ...  1.24067096e-03\n",
      "   5.68206803e-04 -4.44483916e-02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  3.83367365e-03\n",
      "   5.69453250e-03  4.95882413e-03]\n",
      " [ 3.00071134e-01  1.17301771e-04  6.42556211e-04 ...  1.02780241e-03\n",
      "   4.23757265e-04 -3.90654615e-01]\n",
      " ...\n",
      " [ 5.01603488e-01  1.85171506e-02  9.41596130e-03 ...  1.95964581e-02\n",
      "   6.74493141e-03  5.85352367e-03]\n",
      " [ 3.51781247e-02  1.31016833e-02  2.94608308e-03 ...  1.08392660e-03\n",
      "   8.95282153e-04 -5.93716913e-01]\n",
      " [ 2.39558209e-01  4.11295148e-03  4.07374711e-03 ...  7.91682949e-04\n",
      "   1.52512846e-05 -1.73201898e-01]]\n",
      "Initial Output Layer Weights:\n",
      " [[-0.05235681]\n",
      " [-0.06929885]\n",
      " [ 0.01778971]\n",
      " [-0.073722  ]\n",
      " [ 0.05071952]\n",
      " [ 0.07859911]\n",
      " [-0.05125554]\n",
      " [ 0.04294643]\n",
      " [ 0.09425819]\n",
      " [-0.07668326]\n",
      " [ 0.05180435]\n",
      " [ 0.06703467]\n",
      " [-0.0479118 ]\n",
      " [ 0.03165141]\n",
      " [ 0.09045589]\n",
      " [ 0.09812409]\n",
      " [ 0.01055396]\n",
      " [-0.09922259]\n",
      " [-0.00644769]\n",
      " [ 0.0113918 ]\n",
      " [-0.03503728]\n",
      " [-0.00112278]\n",
      " [-0.0798749 ]\n",
      " [ 0.06341098]\n",
      " [ 0.00322935]\n",
      " [-0.03471681]\n",
      " [ 0.03642632]\n",
      " [-0.04266606]\n",
      " [-0.01284711]\n",
      " [-0.07991653]\n",
      " [ 0.02402054]\n",
      " [-0.01020188]\n",
      " [ 0.08643575]\n",
      " [ 0.0554301 ]\n",
      " [ 0.07517409]\n",
      " [-0.04590636]\n",
      " [ 0.05747645]\n",
      " [ 0.03986308]\n",
      " [ 0.08680103]\n",
      " [ 0.01821295]\n",
      " [-0.08228938]\n",
      " [ 0.08996286]\n",
      " [-0.09623899]\n",
      " [ 0.07613449]\n",
      " [ 0.08423999]\n",
      " [-0.00123495]\n",
      " [ 0.08288861]\n",
      " [ 0.027439  ]\n",
      " [ 0.06873616]\n",
      " [ 0.01787321]\n",
      " [-0.08746065]\n",
      " [-0.01995249]\n",
      " [ 0.04865431]\n",
      " [ 0.09657286]\n",
      " [ 0.07517169]\n",
      " [-0.04658041]\n",
      " [ 0.00762341]\n",
      " [ 0.01329317]\n",
      " [ 0.06854638]\n",
      " [ 0.0289398 ]\n",
      " [-0.09972131]\n",
      " [ 0.06175508]\n",
      " [ 0.0549299 ]\n",
      " [ 0.04466419]\n",
      " [ 0.02887709]\n",
      " [ 0.02952594]\n",
      " [-0.04427572]\n",
      " [ 0.0521195 ]\n",
      " [ 0.06443284]\n",
      " [ 0.01571552]\n",
      " [-0.08908858]\n",
      " [ 0.02268251]\n",
      " [-0.08051258]\n",
      " [-0.01132108]\n",
      " [-0.04269816]\n",
      " [ 0.04343707]\n",
      " [-0.06960663]\n",
      " [-0.08191697]\n",
      " [ 0.04560022]\n",
      " [ 0.03151331]\n",
      " [-0.05913276]\n",
      " [-0.00718542]\n",
      " [-0.07160273]\n",
      " [-0.03485943]\n",
      " [-0.05880684]\n",
      " [-0.07573619]\n",
      " [-0.03500312]\n",
      " [ 0.07145044]\n",
      " [ 0.04062798]\n",
      " [-0.04145793]\n",
      " [-0.0143693 ]\n",
      " [ 0.06090951]\n",
      " [ 0.01533826]\n",
      " [-0.07533697]\n",
      " [-0.04169913]\n",
      " [ 0.0608134 ]\n",
      " [ 0.06955433]\n",
      " [ 0.02811363]\n",
      " [-0.06299072]\n",
      " [-0.02555177]\n",
      " [-0.02070497]\n",
      " [ 0.0141634 ]\n",
      " [-0.0691905 ]\n",
      " [ 0.02919119]\n",
      " [ 0.06718831]\n",
      " [-0.09803571]\n",
      " [ 0.08450172]\n",
      " [-0.05981447]\n",
      " [ 0.04677773]\n",
      " [ 0.02961996]\n",
      " [ 0.00605583]\n",
      " [ 0.0695543 ]\n",
      " [-0.03918383]\n",
      " [-0.08404282]\n",
      " [ 0.04806576]\n",
      " [-0.04890317]\n",
      " [-0.06231847]\n",
      " [ 0.01452844]\n",
      " [ 0.08138254]\n",
      " [ 0.0185922 ]\n",
      " [-0.0652954 ]\n",
      " [ 0.09688793]\n",
      " [-0.02095283]\n",
      " [ 0.05393459]\n",
      " [ 0.04015158]\n",
      " [-0.0075568 ]\n",
      " [ 0.01538132]\n",
      " [ 0.02390695]\n",
      " [ 0.09005376]\n",
      " [ 0.05966352]\n",
      " [-0.05264441]\n",
      " [ 0.08986298]\n",
      " [ 0.03118228]\n",
      " [ 0.01000584]\n",
      " [ 0.00473225]\n",
      " [ 0.04793236]\n",
      " [-0.05191016]\n",
      " [-0.03425363]\n",
      " [-0.05301243]\n",
      " [ 0.02588976]\n",
      " [-0.01769062]\n",
      " [ 0.02276784]\n",
      " [ 0.05217506]\n",
      " [-0.06634948]\n",
      " [-0.01330544]\n",
      " [-0.08677133]\n",
      " [ 0.04913662]\n",
      " [-0.08951891]\n",
      " [ 0.09924186]\n",
      " [ 0.03995891]\n",
      " [-0.00137269]\n",
      " [ 0.06378516]\n",
      " [-0.09483097]\n",
      " [-0.07897353]\n",
      " [-0.06501483]\n",
      " [-0.05381736]\n",
      " [ 0.08419775]\n",
      " [-0.01488589]\n",
      " [ 0.0374936 ]\n",
      " [-0.03586027]\n",
      " [ 0.04062636]\n",
      " [-0.02713976]\n",
      " [ 0.04522429]\n",
      " [-0.0859797 ]\n",
      " [-0.05705918]\n",
      " [ 0.09147431]\n",
      " [ 0.03585664]\n",
      " [-0.01784033]\n",
      " [-0.07616841]\n",
      " [ 0.08243383]\n",
      " [ 0.05000236]\n",
      " [-0.09153374]\n",
      " [-0.04063605]\n",
      " [ 0.0006541 ]\n",
      " [-0.08813457]\n",
      " [ 0.04024693]\n",
      " [-0.04035509]\n",
      " [-0.01166812]\n",
      " [ 0.0576461 ]\n",
      " [-0.06184859]\n",
      " [-0.07285563]\n",
      " [ 0.00190656]\n",
      " [ 0.06198264]\n",
      " [ 0.0843981 ]\n",
      " [-0.08229459]\n",
      " [-0.03481597]\n",
      " [-0.09675287]\n",
      " [ 0.05932935]\n",
      " [-0.01343971]\n",
      " [-0.03986869]\n",
      " [ 0.04602915]\n",
      " [-0.05962453]\n",
      " [-0.05851396]\n",
      " [ 0.0558567 ]\n",
      " [-0.03798603]\n",
      " [-0.01133181]\n",
      " [-0.01227832]\n",
      " [ 0.07852216]\n",
      " [ 0.03400812]\n",
      " [-0.0328669 ]]\n",
      "Initial Hidden Layer Weights:\n",
      " [[-0.00663801 -0.0794941   0.02036023 ...  0.03633531  0.0301032\n",
      "  -0.00151336]\n",
      " [ 0.0796966   0.05831015  0.09344995 ... -0.07076615  0.06453402\n",
      "  -0.04468123]\n",
      " [-0.03255854  0.09830897  0.09504995 ...  0.04754366 -0.04174854\n",
      "  -0.02688107]\n",
      " ...\n",
      " [-0.07613073  0.02562035 -0.05542652 ... -0.03782952 -0.00217822\n",
      "  -0.04842494]\n",
      " [-0.01948577 -0.02898763 -0.02738672 ... -0.041171    0.02424\n",
      "   0.00068266]\n",
      " [-0.00666045  0.04437086  0.04550986 ...  0.00694504  0.02259874\n",
      "   0.03481388]]\n",
      "Initial Output Layer Bias:\n",
      " [[-1.]]\n",
      "Initial Hidden Layer Bias:\n",
      " [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1.]]\n",
      "Final Output Layer Weights:\n",
      " [[-0.05759203]\n",
      " [-0.06929885]\n",
      " [ 0.01778971]\n",
      " [-0.08493846]\n",
      " [ 0.04934073]\n",
      " [ 0.07859911]\n",
      " [-0.05125554]\n",
      " [ 0.03713557]\n",
      " [ 0.08969476]\n",
      " [-0.07668326]\n",
      " [ 0.05062199]\n",
      " [ 0.06702786]\n",
      " [-0.0479118 ]\n",
      " [ 0.03165141]\n",
      " [ 0.09045589]\n",
      " [ 0.09812409]\n",
      " [ 0.01055396]\n",
      " [-0.09922259]\n",
      " [-0.00644769]\n",
      " [ 0.00862753]\n",
      " [-0.03503728]\n",
      " [-0.00112278]\n",
      " [-0.08203856]\n",
      " [ 0.06334091]\n",
      " [ 0.00322935]\n",
      " [-0.0605763 ]\n",
      " [ 0.03642632]\n",
      " [-0.04266606]\n",
      " [-0.01284711]\n",
      " [-0.07991653]\n",
      " [ 0.02100222]\n",
      " [-0.01020188]\n",
      " [ 0.08643575]\n",
      " [ 0.0554301 ]\n",
      " [ 0.07517032]\n",
      " [-0.04590636]\n",
      " [ 0.05747645]\n",
      " [ 0.03797511]\n",
      " [ 0.08317758]\n",
      " [ 0.01635812]\n",
      " [-0.0844016 ]\n",
      " [ 0.08996286]\n",
      " [-0.09691299]\n",
      " [ 0.06949768]\n",
      " [ 0.08423999]\n",
      " [-0.00123495]\n",
      " [ 0.08094378]\n",
      " [ 0.027439  ]\n",
      " [ 0.06855906]\n",
      " [ 0.01345212]\n",
      " [-0.08746065]\n",
      " [-0.01995249]\n",
      " [ 0.04865431]\n",
      " [ 0.08167969]\n",
      " [ 0.07517169]\n",
      " [-0.04658041]\n",
      " [-0.00378042]\n",
      " [ 0.0129283 ]\n",
      " [ 0.06854638]\n",
      " [ 0.0289398 ]\n",
      " [-0.09972131]\n",
      " [ 0.06175508]\n",
      " [ 0.0549299 ]\n",
      " [ 0.04394549]\n",
      " [ 0.02849738]\n",
      " [ 0.02012601]\n",
      " [-0.04466753]\n",
      " [ 0.0521195 ]\n",
      " [ 0.06443284]\n",
      " [ 0.01570506]\n",
      " [-0.08908858]\n",
      " [ 0.02268251]\n",
      " [-0.08051258]\n",
      " [-0.01271914]\n",
      " [-0.04269816]\n",
      " [ 0.02563519]\n",
      " [-0.07033548]\n",
      " [-0.08191697]\n",
      " [ 0.04520668]\n",
      " [ 0.03151331]\n",
      " [-0.05913276]\n",
      " [-0.06185569]\n",
      " [-0.07160273]\n",
      " [-0.04373414]\n",
      " [-0.05880684]\n",
      " [-0.07650469]\n",
      " [-0.03500312]\n",
      " [ 0.06974084]\n",
      " [ 0.01716742]\n",
      " [-0.04183012]\n",
      " [-0.01494895]\n",
      " [ 0.06090951]\n",
      " [ 0.01518224]\n",
      " [-0.08611841]\n",
      " [-0.04169913]\n",
      " [ 0.05236902]\n",
      " [ 0.05889323]\n",
      " [ 0.01906685]\n",
      " [-0.06685267]\n",
      " [-0.02805546]\n",
      " [-0.02070497]\n",
      " [ 0.0141634 ]\n",
      " [-0.0691905 ]\n",
      " [ 0.02919119]\n",
      " [ 0.06718831]\n",
      " [-0.10163028]\n",
      " [ 0.08450172]\n",
      " [-0.05999501]\n",
      " [ 0.04228136]\n",
      " [ 0.02849287]\n",
      " [ 0.00310963]\n",
      " [ 0.0690498 ]\n",
      " [-0.06215899]\n",
      " [-0.08404282]\n",
      " [ 0.04806576]\n",
      " [-0.04890317]\n",
      " [-0.06231847]\n",
      " [ 0.01452844]\n",
      " [ 0.08138254]\n",
      " [ 0.0185922 ]\n",
      " [-0.0652954 ]\n",
      " [ 0.09688793]\n",
      " [-0.02401837]\n",
      " [ 0.05305915]\n",
      " [ 0.04015158]\n",
      " [-0.0075568 ]\n",
      " [ 0.01438143]\n",
      " [ 0.02390695]\n",
      " [ 0.09005376]\n",
      " [ 0.05966352]\n",
      " [-0.05390687]\n",
      " [ 0.08986298]\n",
      " [ 0.03118228]\n",
      " [ 0.00950447]\n",
      " [ 0.00125586]\n",
      " [ 0.04793236]\n",
      " [-0.05191016]\n",
      " [-0.04356919]\n",
      " [-0.05596774]\n",
      " [ 0.02406622]\n",
      " [-0.01769062]\n",
      " [ 0.02276784]\n",
      " [ 0.05217506]\n",
      " [-0.06634948]\n",
      " [-0.01725221]\n",
      " [-0.08677133]\n",
      " [ 0.04913662]\n",
      " [-0.08951891]\n",
      " [ 0.09924186]\n",
      " [ 0.03995891]\n",
      " [-0.00137269]\n",
      " [ 0.06378516]\n",
      " [-0.09483097]\n",
      " [-0.07930887]\n",
      " [-0.065909  ]\n",
      " [-0.05554934]\n",
      " [ 0.08419775]\n",
      " [-0.01488589]\n",
      " [ 0.0374936 ]\n",
      " [-0.03586027]\n",
      " [ 0.03691117]\n",
      " [-0.02998202]\n",
      " [ 0.04295558]\n",
      " [-0.0859797 ]\n",
      " [-0.05714786]\n",
      " [ 0.09147431]\n",
      " [ 0.03585664]\n",
      " [-0.04294112]\n",
      " [-0.07616841]\n",
      " [ 0.08243383]\n",
      " [ 0.04705908]\n",
      " [-0.09153374]\n",
      " [-0.04063605]\n",
      " [ 0.0006541 ]\n",
      " [-0.08813457]\n",
      " [ 0.04024693]\n",
      " [-0.04035509]\n",
      " [-0.01194835]\n",
      " [ 0.05658967]\n",
      " [-0.06184859]\n",
      " [-0.07285563]\n",
      " [ 0.00190656]\n",
      " [ 0.04446511]\n",
      " [ 0.0843981 ]\n",
      " [-0.08229459]\n",
      " [-0.03757033]\n",
      " [-0.09718677]\n",
      " [ 0.05783646]\n",
      " [-0.01343971]\n",
      " [-0.04065486]\n",
      " [ 0.04602915]\n",
      " [-0.05962453]\n",
      " [-0.05851396]\n",
      " [ 0.0558567 ]\n",
      " [-0.03798603]\n",
      " [-0.01133181]\n",
      " [-0.01227832]\n",
      " [ 0.07852216]\n",
      " [ 0.03400812]\n",
      " [-0.0328669 ]]\n",
      "Final Hidden Layer Weights:\n",
      " [[-0.00655871 -0.0794941   0.02036023 ...  0.03633531  0.0301032\n",
      "  -0.00151336]\n",
      " [ 0.07969964  0.05831015  0.09344995 ... -0.07076615  0.06453402\n",
      "  -0.04468123]\n",
      " [-0.03255616  0.09830897  0.09504995 ...  0.04754366 -0.04174854\n",
      "  -0.02688107]\n",
      " ...\n",
      " [-0.07612297  0.02562035 -0.05542652 ... -0.03782952 -0.00217822\n",
      "  -0.04842494]\n",
      " [-0.01947641 -0.02898763 -0.02738672 ... -0.041171    0.02424\n",
      "   0.00068266]\n",
      " [-0.00690847  0.04437086  0.04550986 ...  0.00694504  0.02259874\n",
      "   0.03481388]]\n",
      "Final Output Layer Bias:\n",
      " [[-1.04924886]]\n",
      "Final Hidden Layer Bias:\n",
      " [[-1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958 -1.0005958\n",
      "  -1.0005958 -1.0005958]]\n",
      "Target Output:\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "After Training:\n",
      " [[0.24521206]\n",
      " [0.21242965]\n",
      " [0.23020244]\n",
      " [0.20771542]\n",
      " [0.23207016]\n",
      " [0.22543328]\n",
      " [0.25233353]\n",
      " [0.21140064]\n",
      " [0.24079676]\n",
      " [0.23561092]]\n",
      "No human detected and the predicted output is [0.24521206]\n",
      "No human detected and the predicted output is [0.21242965]\n",
      "No human detected and the predicted output is [0.23020244]\n",
      "No human detected and the predicted output is [0.20771542]\n",
      "No human detected and the predicted output is [0.23207016]\n",
      "No human detected and the predicted output is [0.22543328]\n",
      "No human detected and the predicted output is [0.25233353]\n",
      "No human detected and the predicted output is [0.21140064]\n",
      "No human detected and the predicted output is [0.24079676]\n",
      "No human detected and the predicted output is [0.23561092]\n",
      "Average error =  2.5715116960422995\n",
      "00000003a_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 0.00282663  0.00134587  0.00228056 ...  0.00215529  0.00103661\n",
      "  -0.33881455]]\n",
      "00000090a_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 0.00282663  0.00134587  0.00228056 ...  0.00215529  0.00103661\n",
      "  -0.33881455]\n",
      " [ 0.          0.          0.         ...  0.21102339  0.16180318\n",
      "   0.10546461]]\n",
      "00000118a_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 2.82663104e-03  1.34586736e-03  2.28055647e-03 ...  2.15529063e-03\n",
      "   1.03661228e-03 -3.38814552e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.11023390e-01\n",
      "   1.61803176e-01  1.05464606e-01]\n",
      " [ 4.41997552e-02  2.90398920e-04  3.30040248e-04 ...  2.65419103e-03\n",
      "   1.60772629e-03 -3.08067259e-01]]\n",
      "no_person__no_bike_258_Cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 2.82663104e-03  1.34586736e-03  2.28055647e-03 ...  2.15529063e-03\n",
      "   1.03661228e-03 -3.38814552e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.11023390e-01\n",
      "   1.61803176e-01  1.05464606e-01]\n",
      " [ 4.41997552e-02  2.90398920e-04  3.30040248e-04 ...  2.65419103e-03\n",
      "   1.60772629e-03 -3.08067259e-01]\n",
      " [ 1.70074460e-01  1.50400852e-03  6.19860620e-03 ...  1.70460593e-02\n",
      "   1.70401046e-02 -3.77156939e-01]]\n",
      "no_person__no_bike_264_cut.bmp\n",
      "160\n",
      "209\n",
      "(7524,)\n",
      "[[ 2.82663104e-03  1.34586736e-03  2.28055647e-03 ...  2.15529063e-03\n",
      "   1.03661228e-03 -3.38814552e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.11023390e-01\n",
      "   1.61803176e-01  1.05464606e-01]\n",
      " [ 4.41997552e-02  2.90398920e-04  3.30040248e-04 ...  2.65419103e-03\n",
      "   1.60772629e-03 -3.08067259e-01]\n",
      " [ 1.70074460e-01  1.50400852e-03  6.19860620e-03 ...  1.70460593e-02\n",
      "   1.70401046e-02 -3.77156939e-01]\n",
      " [ 5.23606715e-01  2.97657309e-02  1.04153520e-02 ...  3.08571522e-02\n",
      "   6.98046581e-03 -1.91315243e-01]]\n",
      "Initial Output Layer Weights:\n",
      " [[ 0.02823818]\n",
      " [-0.01888836]\n",
      " [-0.09300822]\n",
      " [ 0.03254166]\n",
      " [ 0.02133908]\n",
      " [ 0.01006426]\n",
      " [-0.00617829]\n",
      " [ 0.05117701]\n",
      " [ 0.09711783]\n",
      " [ 0.01212502]\n",
      " [-0.03116975]\n",
      " [ 0.04972187]\n",
      " [ 0.01402735]\n",
      " [-0.01282743]\n",
      " [-0.02551741]\n",
      " [-0.02531011]\n",
      " [ 0.00471329]\n",
      " [-0.08837803]\n",
      " [ 0.02438572]\n",
      " [-0.03613115]\n",
      " [-0.0524067 ]\n",
      " [-0.06060694]\n",
      " [-0.07503477]\n",
      " [-0.00258885]\n",
      " [-0.08953651]\n",
      " [-0.06046454]\n",
      " [-0.02304844]\n",
      " [ 0.01529591]\n",
      " [ 0.0091007 ]\n",
      " [-0.02805012]\n",
      " [ 0.03094269]\n",
      " [ 0.0669951 ]\n",
      " [ 0.06321526]\n",
      " [ 0.09057566]\n",
      " [-0.02837247]\n",
      " [ 0.04967158]\n",
      " [-0.08215712]\n",
      " [-0.02631263]\n",
      " [-0.03503465]\n",
      " [-0.02556027]\n",
      " [-0.07680571]\n",
      " [-0.0965297 ]\n",
      " [ 0.07512423]\n",
      " [ 0.0263838 ]\n",
      " [-0.01760016]\n",
      " [ 0.01534746]\n",
      " [-0.0945571 ]\n",
      " [-0.00290781]\n",
      " [-0.04961166]\n",
      " [-0.06127998]\n",
      " [-0.04309882]\n",
      " [ 0.0442274 ]\n",
      " [-0.07692869]\n",
      " [ 0.09064733]\n",
      " [ 0.01338031]\n",
      " [-0.0086331 ]\n",
      " [ 0.09660534]\n",
      " [-0.02169721]\n",
      " [ 0.03018502]\n",
      " [ 0.03539673]\n",
      " [-0.08001818]\n",
      " [ 0.06147301]\n",
      " [-0.02857322]\n",
      " [ 0.00831871]\n",
      " [ 0.04548913]\n",
      " [ 0.09154394]\n",
      " [-0.09915101]\n",
      " [ 0.00295837]\n",
      " [-0.02745685]\n",
      " [ 0.01377876]\n",
      " [-0.09849285]\n",
      " [ 0.09541418]\n",
      " [-0.07991701]\n",
      " [ 0.04300782]\n",
      " [ 0.08299116]\n",
      " [ 0.04452032]\n",
      " [-0.0779522 ]\n",
      " [-0.02931402]\n",
      " [ 0.09285885]\n",
      " [-0.00223935]\n",
      " [-0.03225845]\n",
      " [ 0.06136893]\n",
      " [ 0.09775184]\n",
      " [ 0.01313082]\n",
      " [-0.01314641]\n",
      " [ 0.03872254]\n",
      " [-0.02713237]\n",
      " [ 0.05503039]\n",
      " [ 0.09087775]\n",
      " [ 0.05620538]\n",
      " [-0.05578569]\n",
      " [-0.02503488]\n",
      " [ 0.08868246]\n",
      " [ 0.03182817]\n",
      " [ 0.03343632]\n",
      " [-0.05296156]\n",
      " [ 0.05329947]\n",
      " [ 0.02172174]\n",
      " [ 0.0325263 ]\n",
      " [-0.085026  ]\n",
      " [ 0.09067958]\n",
      " [ 0.00747076]\n",
      " [-0.06729671]\n",
      " [ 0.03894227]\n",
      " [-0.07180367]\n",
      " [-0.08417346]\n",
      " [ 0.04180502]\n",
      " [ 0.05355585]\n",
      " [ 0.07066607]\n",
      " [-0.04771334]\n",
      " [ 0.03270237]\n",
      " [ 0.05999372]\n",
      " [-0.05977466]\n",
      " [-0.09312895]\n",
      " [-0.01701888]\n",
      " [ 0.08617512]\n",
      " [-0.04572979]\n",
      " [-0.09465609]\n",
      " [ 0.03855559]\n",
      " [-0.07364722]\n",
      " [ 0.07960861]\n",
      " [ 0.00153558]\n",
      " [ 0.04154495]\n",
      " [ 0.03571723]\n",
      " [ 0.07960955]\n",
      " [ 0.06398968]\n",
      " [-0.0212611 ]\n",
      " [ 0.08733511]\n",
      " [-0.01000498]\n",
      " [-0.07884218]\n",
      " [-0.0205089 ]\n",
      " [-0.03513496]\n",
      " [ 0.0585729 ]\n",
      " [-0.00232754]\n",
      " [-0.01359161]\n",
      " [-0.05815997]\n",
      " [-0.00534508]\n",
      " [ 0.04052104]\n",
      " [ 0.0502448 ]\n",
      " [ 0.03064013]\n",
      " [ 0.09593807]\n",
      " [ 0.04896761]\n",
      " [-0.01650538]\n",
      " [ 0.01778803]\n",
      " [ 0.09659537]\n",
      " [ 0.05578461]\n",
      " [ 0.04919684]\n",
      " [ 0.0477664 ]\n",
      " [ 0.04991095]\n",
      " [ 0.07580737]\n",
      " [ 0.01313421]\n",
      " [-0.08852044]\n",
      " [-0.01949388]\n",
      " [ 0.06750832]\n",
      " [-0.09165351]\n",
      " [-0.06596052]\n",
      " [-0.02681192]\n",
      " [ 0.04073851]\n",
      " [-0.02177587]\n",
      " [ 0.09894942]\n",
      " [-0.00075343]\n",
      " [-0.01880574]\n",
      " [-0.0647396 ]\n",
      " [-0.05356483]\n",
      " [ 0.07703674]\n",
      " [-0.00229512]\n",
      " [ 0.08437467]\n",
      " [ 0.01612715]\n",
      " [ 0.08334901]\n",
      " [ 0.01861292]\n",
      " [-0.01503827]\n",
      " [ 0.07180148]\n",
      " [-0.07221814]\n",
      " [ 0.0135565 ]\n",
      " [-0.09284856]\n",
      " [-0.01936213]\n",
      " [-0.05295765]\n",
      " [ 0.06084194]\n",
      " [ 0.01445899]\n",
      " [ 0.00227513]\n",
      " [-0.02177341]\n",
      " [ 0.01087007]\n",
      " [ 0.0073845 ]\n",
      " [-0.09843722]\n",
      " [-0.01902475]\n",
      " [ 0.05554669]\n",
      " [-0.01360165]\n",
      " [-0.02211289]\n",
      " [ 0.06938761]\n",
      " [-0.08299681]\n",
      " [ 0.08768081]\n",
      " [-0.07400974]\n",
      " [-0.07381666]\n",
      " [ 0.03899048]\n",
      " [ 0.02139707]\n",
      " [-0.08482863]\n",
      " [ 0.06529345]\n",
      " [ 0.07029896]\n",
      " [-0.05011389]\n",
      " [-0.06578395]]\n",
      "Initial Hidden Layer Weights:\n",
      " [[-0.01083777  0.0347404  -0.0729284  ... -0.08736009 -0.01675601\n",
      "   0.0488091 ]\n",
      " [ 0.08868173 -0.00269349  0.08539675 ...  0.02848738  0.00137293\n",
      "  -0.03437988]\n",
      " [-0.00078572 -0.03702439  0.00890952 ... -0.09909909 -0.06997427\n",
      "  -0.05783815]\n",
      " ...\n",
      " [-0.09410445  0.03371041 -0.07896802 ... -0.0809376  -0.02979131\n",
      "   0.03230917]\n",
      " [ 0.09106629 -0.06268169  0.07195144 ...  0.04074116 -0.09109332\n",
      "  -0.05265188]\n",
      " [-0.05293391  0.0349712  -0.02059997 ...  0.07367802 -0.00993816\n",
      "  -0.04077779]]\n",
      "Initial Output Layer Bias:\n",
      " [[-1.]]\n",
      "Initial Hidden Layer Bias:\n",
      " [[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      "  -1. -1.]]\n",
      "Final Output Layer Weights:\n",
      " [[ 0.02823818]\n",
      " [-0.01888836]\n",
      " [-0.0937505 ]\n",
      " [ 0.03254166]\n",
      " [ 0.0211786 ]\n",
      " [ 0.01006426]\n",
      " [-0.00617829]\n",
      " [ 0.05117701]\n",
      " [ 0.09711783]\n",
      " [ 0.01030159]\n",
      " [-0.03129139]\n",
      " [ 0.04972187]\n",
      " [ 0.01384747]\n",
      " [-0.01282743]\n",
      " [-0.02551741]\n",
      " [-0.02568577]\n",
      " [ 0.00471329]\n",
      " [-0.08837803]\n",
      " [ 0.02438572]\n",
      " [-0.03613115]\n",
      " [-0.0524067 ]\n",
      " [-0.06060694]\n",
      " [-0.07535072]\n",
      " [-0.00258885]\n",
      " [-0.08953651]\n",
      " [-0.06046454]\n",
      " [-0.02476893]\n",
      " [ 0.01529591]\n",
      " [ 0.0091007 ]\n",
      " [-0.02805012]\n",
      " [ 0.03094269]\n",
      " [ 0.0669951 ]\n",
      " [ 0.06321526]\n",
      " [ 0.09057169]\n",
      " [-0.03163824]\n",
      " [ 0.04967158]\n",
      " [-0.08215712]\n",
      " [-0.02631263]\n",
      " [-0.03503465]\n",
      " [-0.02556027]\n",
      " [-0.08688421]\n",
      " [-0.0965297 ]\n",
      " [ 0.07512423]\n",
      " [ 0.02368239]\n",
      " [-0.01958881]\n",
      " [ 0.01534746]\n",
      " [-0.0945571 ]\n",
      " [-0.00290781]\n",
      " [-0.05042363]\n",
      " [-0.06229968]\n",
      " [-0.04309882]\n",
      " [ 0.0442274 ]\n",
      " [-0.07692869]\n",
      " [ 0.09064733]\n",
      " [ 0.01338031]\n",
      " [-0.0086331 ]\n",
      " [ 0.09656187]\n",
      " [-0.02169721]\n",
      " [ 0.02998344]\n",
      " [ 0.03539673]\n",
      " [-0.08001818]\n",
      " [ 0.06147301]\n",
      " [-0.0325426 ]\n",
      " [ 0.00831871]\n",
      " [ 0.04548913]\n",
      " [ 0.09154394]\n",
      " [-0.10070925]\n",
      " [ 0.00295837]\n",
      " [-0.02745685]\n",
      " [ 0.00926804]\n",
      " [-0.09849285]\n",
      " [ 0.09541418]\n",
      " [-0.07991701]\n",
      " [ 0.04300782]\n",
      " [ 0.08284489]\n",
      " [ 0.04452032]\n",
      " [-0.0779522 ]\n",
      " [-0.02931402]\n",
      " [ 0.09285885]\n",
      " [-0.00223935]\n",
      " [-0.03225845]\n",
      " [ 0.06136893]\n",
      " [ 0.09734403]\n",
      " [ 0.01313082]\n",
      " [-0.01314641]\n",
      " [ 0.03872254]\n",
      " [-0.02713237]\n",
      " [ 0.05503039]\n",
      " [ 0.09087775]\n",
      " [ 0.05025705]\n",
      " [-0.05821368]\n",
      " [-0.02503488]\n",
      " [ 0.08868246]\n",
      " [ 0.03070132]\n",
      " [ 0.03343632]\n",
      " [-0.05296156]\n",
      " [ 0.05329947]\n",
      " [ 0.01239677]\n",
      " [ 0.0325263 ]\n",
      " [-0.085026  ]\n",
      " [ 0.09067958]\n",
      " [ 0.00682053]\n",
      " [-0.06729671]\n",
      " [ 0.03894227]\n",
      " [-0.07180367]\n",
      " [-0.08417346]\n",
      " [ 0.04117856]\n",
      " [ 0.05355585]\n",
      " [ 0.07066607]\n",
      " [-0.04771334]\n",
      " [ 0.03270237]\n",
      " [ 0.05930056]\n",
      " [-0.05977466]\n",
      " [-0.09312895]\n",
      " [-0.01701888]\n",
      " [ 0.08617512]\n",
      " [-0.04572979]\n",
      " [-0.09465609]\n",
      " [ 0.03855559]\n",
      " [-0.07364722]\n",
      " [ 0.07960861]\n",
      " [ 0.00153558]\n",
      " [ 0.03928206]\n",
      " [ 0.03561809]\n",
      " [ 0.07960955]\n",
      " [ 0.06398968]\n",
      " [-0.02409384]\n",
      " [ 0.08733511]\n",
      " [-0.01427883]\n",
      " [-0.07884218]\n",
      " [-0.02127057]\n",
      " [-0.03604445]\n",
      " [ 0.0585729 ]\n",
      " [-0.00232754]\n",
      " [-0.01359161]\n",
      " [-0.05931897]\n",
      " [-0.00534508]\n",
      " [ 0.04052104]\n",
      " [ 0.04836918]\n",
      " [ 0.03064013]\n",
      " [ 0.09593807]\n",
      " [ 0.04896761]\n",
      " [-0.01659117]\n",
      " [ 0.01778803]\n",
      " [ 0.09622296]\n",
      " [ 0.05416014]\n",
      " [ 0.0465893 ]\n",
      " [ 0.0477664 ]\n",
      " [ 0.04991095]\n",
      " [ 0.07580737]\n",
      " [ 0.0105242 ]\n",
      " [-0.09451834]\n",
      " [-0.01949388]\n",
      " [ 0.06750832]\n",
      " [-0.09165351]\n",
      " [-0.06797713]\n",
      " [-0.02681192]\n",
      " [ 0.03954188]\n",
      " [-0.02465897]\n",
      " [ 0.09894942]\n",
      " [-0.00075343]\n",
      " [-0.02003495]\n",
      " [-0.0647396 ]\n",
      " [-0.05617135]\n",
      " [ 0.07703674]\n",
      " [-0.00519894]\n",
      " [ 0.08437467]\n",
      " [ 0.01612715]\n",
      " [ 0.08334901]\n",
      " [ 0.01861292]\n",
      " [-0.01503827]\n",
      " [ 0.07180148]\n",
      " [-0.07221814]\n",
      " [ 0.00883735]\n",
      " [-0.09284856]\n",
      " [-0.02224325]\n",
      " [-0.05295765]\n",
      " [ 0.06084194]\n",
      " [ 0.00952729]\n",
      " [ 0.00227513]\n",
      " [-0.02177341]\n",
      " [ 0.00926096]\n",
      " [ 0.0073845 ]\n",
      " [-0.09843722]\n",
      " [-0.02244893]\n",
      " [ 0.05554669]\n",
      " [-0.01360165]\n",
      " [-0.02211289]\n",
      " [ 0.06907987]\n",
      " [-0.08339039]\n",
      " [ 0.08768081]\n",
      " [-0.07400974]\n",
      " [-0.07497276]\n",
      " [ 0.03897275]\n",
      " [ 0.02139707]\n",
      " [-0.08482863]\n",
      " [ 0.06529345]\n",
      " [ 0.07029896]\n",
      " [-0.05027689]\n",
      " [-0.06578395]]\n",
      "Final Hidden Layer Weights:\n",
      " [[-0.01083777  0.0347404  -0.0729284  ... -0.08736009 -0.01671113\n",
      "   0.0488091 ]\n",
      " [ 0.08868173 -0.00269349  0.08539675 ...  0.02848738  0.00137333\n",
      "  -0.03437988]\n",
      " [-0.00078572 -0.03702439  0.00890952 ... -0.09909909 -0.06997264\n",
      "  -0.05783815]\n",
      " ...\n",
      " [-0.09410445  0.03371041 -0.07887386 ... -0.0809376  -0.02978682\n",
      "   0.03230917]\n",
      " [ 0.09106629 -0.06268169  0.07202364 ...  0.04074116 -0.09108882\n",
      "  -0.05265188]\n",
      " [-0.05293391  0.0349712  -0.02055291 ...  0.07367802 -0.01003769\n",
      "  -0.04077779]]\n",
      "Final Output Layer Bias:\n",
      " [[-1.02396922]]\n",
      "Final Hidden Layer Bias:\n",
      " [[-0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189 -0.99843189\n",
      "  -0.99843189 -0.99843189]]\n",
      "Target Output:\n",
      " [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "After Training:\n",
      " [[0.23349042]\n",
      " [0.24463926]\n",
      " [0.25850031]\n",
      " [0.26025503]\n",
      " [0.229137  ]]\n",
      "No human detected and the predicted output is [0.23349042]\n",
      "No human detected and the predicted output is [0.24463926]\n",
      "No human detected and the predicted output is [0.25850031]\n",
      "No human detected and the predicted output is [0.26025503]\n",
      "No human detected and the predicted output is [0.229137]\n",
      "Average error =  2.5324716210612928\n"
     ]
    }
   ],
   "source": [
    "class Driver:\n",
    "    if __name__ == '__main__':\n",
    "        \n",
    "        train_path_positive = \"C://Users//anvit//OneDrive//Desktop//HoG//Training_images(Pos)\"\n",
    "        train_path_negative = \"C://Users//anvit//OneDrive//Desktop//HoG//Training_images(Neg)\"\n",
    "        test_neg = \"C://Users//anvit//OneDrive//Desktop//HoG//Test_images(Neg)\"\n",
    "        test_pos = \"C://Users//anvit//OneDrive//Desktop//HoG//Test_images(Pos)\"\n",
    "        \n",
    "        def gen_hog_vectors(path):\n",
    "            vectors = []\n",
    "            files = os.listdir(path)\n",
    "            for file in files:\n",
    "                print(file)\n",
    "                t = Preprocessing(path + '//' + file)\n",
    "                image = t.img_array\n",
    "#         print(image)\n",
    "                gray = t.gray_array\n",
    "#         print(gray)\n",
    "                g_x = t.g_x\n",
    "#         print(g_x[28][28])\n",
    "                g_y = t.g_y\n",
    "#         print(g_y[28][28])\n",
    "                g_mag = t.g_mag\n",
    "#         print(g_mag[28][28])\n",
    "                theta = t.theta\n",
    "#         print(theta[28][28])\n",
    "                h_feature_output = np.array(h_feature(g_mag,theta))\n",
    "                print(h_feature_output.shape)\n",
    "#                 h_feature_output = h_feature(g_mag,theta)\n",
    "                vectors.append(h_feature_output)\n",
    "                result = np.array(vectors)\n",
    "                print(result)\n",
    "            return result\n",
    "\n",
    "        hidden_layer_weights = 0\n",
    "        output_layer_weights = 0\n",
    "\n",
    "        # bias:\n",
    "        hidden_layer_bias = 0\n",
    "        output_layer_bias = 0\n",
    "        \n",
    "        def train_nn(inputs,target_output):\n",
    "            \n",
    "            epochs = 10\n",
    "            alpha = 0.01\n",
    "            input_layer_neurons = 7524\n",
    "            hidden_layer_neurons = 200\n",
    "            output_layer_neurons = 1\n",
    "            err = 0\n",
    "            \n",
    "#             inputs = np.array([[0,0],[0,1],[1,0], [1,1]])\n",
    "#             target_output = np.array([[0],[1],[1],[0]]) \n",
    "            \n",
    "            # Step 1: Initialize the weights and biases to have random values between −0.5 and 0.5:\n",
    "#             weights\n",
    "            hidden_layer_weights = np.random.uniform(-0.5,0.5, size = (input_layer_neurons,hidden_layer_neurons)) * 2 * 0.1\n",
    "            output_layer_weights = np.random.uniform(-0.5,0.5, size = (hidden_layer_neurons,output_layer_neurons)) * 2 * 0.1\n",
    "\n",
    "            # bias:\n",
    "            hidden_layer_bias = np.random.uniform(-1.0, -1.0,size = (1,hidden_layer_neurons))\n",
    "            output_layer_bias = np.random.uniform(-1.0, -1.0,size = (1,output_layer_neurons))\n",
    "\n",
    "            print('Initial Output Layer Weights:\\n', output_layer_weights)\n",
    "            print('Initial Hidden Layer Weights:\\n', hidden_layer_weights)\n",
    "            print('Initial Output Layer Bias:\\n', output_layer_bias)\n",
    "            print('Initial Hidden Layer Bias:\\n', hidden_layer_bias)\n",
    "                \n",
    "            # Step 2: Training the inputs\n",
    "\n",
    "            # Step 2a:\n",
    "            # Setting the corresponding activation(a1) for input_layer\n",
    "            def sigmoid(x):\n",
    "                return 1/(1 + np.exp(-x))\n",
    "\n",
    "            # We need the derivative of this for further calculations\n",
    "            def derivative_of_sigmoid(x):\n",
    "            #     derivative of sigmoid in terms of itslef is:\n",
    "                return x * (1 - x)\n",
    "            \n",
    "            def relu(x):\n",
    "                y = x.copy()\n",
    "                y[x<0] = 0\n",
    "                return y\n",
    "        \n",
    "            # Derivative of ReLU in terms of itself is:    \n",
    "            def derivative_of_relu(x):\n",
    "                y = x.copy()\n",
    "                y[x>0] = 1\n",
    "                y[x<=0] = 0\n",
    "                return y\n",
    "\n",
    "            for i in range(epochs):\n",
    "                #     Step 2b:\n",
    "                #     Feedforward\n",
    "                h_layer_a = np.dot(inputs, hidden_layer_weights)\n",
    "                h_layer_a = h_layer_a + hidden_layer_bias\n",
    "                output_hidden_layer = relu(h_layer_a)\n",
    "    \n",
    "                o_layer_a = np.dot(output_hidden_layer, output_layer_weights)\n",
    "                o_layer_a = o_layer_a + output_layer_bias\n",
    "                pred_output = sigmoid(o_layer_a)\n",
    "\n",
    "                #     Step 2c:\n",
    "                #     Output error\n",
    "                \n",
    "                final_error = target_output - pred_output\n",
    "                err = err + np.absolute(target_output - pred_output).sum()\n",
    "                pred_output_delta = final_error * derivative_of_sigmoid(pred_output)\n",
    "\n",
    "                #     Step 2d:\n",
    "                #     Backpropogating the error\n",
    "                h_layer_error = pred_output_delta.dot(output_layer_weights.T)\n",
    "                hidden_layer_output_delta = h_layer_error * derivative_of_relu(output_hidden_layer)\n",
    "\n",
    "                #     Step 2e:\n",
    "                #     Updating weights and bias\n",
    "                output_layer_weights = output_layer_weights + output_hidden_layer.T.dot(pred_output_delta) * alpha\n",
    "                output_layer_bias = output_layer_bias + np.sum(pred_output_delta) * alpha\n",
    "    \n",
    "                hidden_layer_weights = hidden_layer_weights + inputs.T.dot(hidden_layer_output_delta) * alpha\n",
    "                hidden_layer_bias = hidden_layer_bias + np.sum(hidden_layer_output_delta) * alpha\n",
    "\n",
    "            print('Final Output Layer Weights:\\n', output_layer_weights)\n",
    "            print('Final Hidden Layer Weights:\\n', hidden_layer_weights)\n",
    "            print('Final Output Layer Bias:\\n', output_layer_bias)\n",
    "            print('Final Hidden Layer Bias:\\n', hidden_layer_bias)\n",
    "\n",
    "            print('Target Output:\\n', target_output)\n",
    "            print('After Training:\\n', pred_output)\n",
    "            for i in range(pred_output.shape[0]):\n",
    "                if(pred_output[i] >= 0.6):\n",
    "                    print('Human detected and the predicted output is', pred_output[i])\n",
    "                if(pred_output[i] > 0.4 and pred_output[i] < 0.6):\n",
    "                    print('Boarderline human detected and the predicted output is', pred_output[i])\n",
    "                if(pred_output[i] <= 0.4):\n",
    "                    print('No human detected and the predicted output is', pred_output[i])\n",
    "            print('Average error = ', err/ (inputs.shape[0]))\n",
    "                    \n",
    "        def test_nn(inputs,target_output):\n",
    "            \n",
    "            epochs = 10\n",
    "            alpha = 0.1\n",
    "            input_layer_neurons = 7524\n",
    "            hidden_layer_neurons = 200\n",
    "            output_layer_neurons = 1\n",
    "            err = 0\n",
    "            \n",
    "#             inputs = np.array([[0,0],[0,1],[1,0], [1,1]])\n",
    "#             target_output = np.array([[0],[1],[1],[0]]) \n",
    "            \n",
    "            # Step 1: Initialize the weights and biases to have random values between −0.5 and 0.5:\n",
    "            # weights\n",
    "#             hidden_layer_weights = np.random.uniform(-0.5,0.5, size = (input_layer_neurons,hidden_layer_neurons)) * 2 * 0.01\n",
    "#             output_layer_weights = np.random.uniform(-0.5,0.5, size = (hidden_layer_neurons,output_layer_neurons)) * 2 * 0.01\n",
    "\n",
    "#             # bias:\n",
    "#             hidden_layer_bias = np.random.uniform(-1.0, -1.0,size = (1,hidden_layer_neurons))\n",
    "#             output_layer_bias = np.random.uniform(-1.0, -1.0,size = (1,output_layer_neurons))\n",
    "\n",
    "            print('Initial Output Layer Weights:\\n', output_layer_weights)\n",
    "            print('Initial Hidden Layer Weights:\\n', hidden_layer_weights)\n",
    "            print('Initial Output Layer Bias:\\n', output_layer_bias)\n",
    "            print('Initial Hidden Layer Bias:\\n', hidden_layer_bias)\n",
    "                \n",
    "            # Step 2: Training the inputs\n",
    "\n",
    "            # Step 2a:\n",
    "            # Setting the corresponding activation(a1) for input_layer\n",
    "            def sigmoid(x):\n",
    "                return 1/(1 + np.exp(-x))\n",
    "\n",
    "            # We need the derivative of this for further calculations\n",
    "            def derivative_of_sigmoid(x):\n",
    "            #     derivative of sigmoid in terms of itslef is:\n",
    "                return x * (1 - x)\n",
    "            \n",
    "            def relu(x):\n",
    "                y = x.copy()\n",
    "                y[x<0] = 0\n",
    "                return y\n",
    "        \n",
    "            # Derivative of ReLU in terms of itself is:    \n",
    "            def derivative_of_relu(x):\n",
    "                y = x.copy()\n",
    "                y[x>0] = 1\n",
    "                y[x<=0] = 0\n",
    "                return y\n",
    "\n",
    "#             for i in range(epochs):\n",
    "                #     Step 2b:\n",
    "                #     Feedforward\n",
    "            h_layer_a = np.dot(inputs, hidden_layer_weights)\n",
    "            h_layer_a = h_layer_a + hidden_layer_bias\n",
    "            output_hidden_layer = relu(h_layer_a)\n",
    "    \n",
    "            o_layer_a = np.dot(output_hidden_layer, output_layer_weights)\n",
    "            o_layer_a = o_layer_a + output_layer_bias\n",
    "            pred_output = sigmoid(o_layer_a)\n",
    "            \n",
    "            print('Target Output:\\n', target_output)\n",
    "            print('After Training:\\n', pred_output)\n",
    "            for i in range(pred_output.shape[0]):\n",
    "                if(pred_output[i] >= 0.6):\n",
    "                    print('Human detected and the predicted output is', pred_output[i])\n",
    "                if(pred_output[i] > 0.4 and pred_output[i] < 0.6):\n",
    "                    print('Boarderline human detected and the predicted output is', pred_output[i])\n",
    "                if(pred_output[i] <= 0.4):\n",
    "                    print('No human detected and the predicted output is', pred_output[i])\n",
    "#             print('Average error = ', err/ (inputs.shape[0]))\n",
    "        \n",
    "#         positive_hog_feature_vectors = gen_hog_vectors(train_path_positive)\n",
    "#         pos_train = train_nn(positive_hog_feature_vectors, target_output = np.full((10,1), 1.0, dtype = float))\n",
    "        negative_hog_feature_vectors = gen_hog_vectors(train_path_negative)\n",
    "        neg_train = train_nn(negative_hog_feature_vectors, target_output = np.full((10,1), 0.0, dtype = float))\n",
    "#         positive_test_features = gen_hog_vectors(test_pos)\n",
    "#         pos_test = test_nn(positive_test_features, target_output = np.full((5,1), 1.0, dtype = float))\n",
    "        negative_test_features = gen_hog_vectors(test_neg)\n",
    "        neg_test = train_nn(negative_test_features, target_output = np.full((5,1), 0.0, dtype = float))\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(3,2)*0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " (0.5 - (-0.5))* np.random.random_sample((3, 2)) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
